{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 查看BROAD数据集目录\n",
    "!ls -l /mnt/BROAD-datasets/video/\n",
    "# 查看文件个数,以training data举例\n",
    "!ls /mnt/BROAD-datasets/video/training |wc -l\n",
    "!ls /mnt/BROAD-datasets/video/validation |wc -l\n",
    "!ls /mnt/BROAD-datasets/video/testing |wc -l\n",
    "# 查看meta.json\n",
    "# !cat /mnt/BROAD-datasets/video/meta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a new dir, when the server is closed, the data saved here still exist\n",
    "!mkdir -p /home/kesci/work/Broad/INFO\n",
    "# copy meta data to the work dir\n",
    "!cp /mnt/BROAD-datasets/video/meta.json /home/kesci/work/Broad/INFO/\n",
    "# show the files and dic in the path,\n",
    "!ls -l /home/kesci/work/Broad/INFO/\n",
    "# show the memory of each dic\n",
    "!du -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls -l /home/kesci/work/\n",
    "!du -ah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_json(file):  ## load json file and return data\n",
    "    with open(file) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data\n",
    "\n",
    "def getDatasetDict():\n",
    "    json_data= load_json(\"/home/kesci/work/Broad/INFO/meta.json\")\n",
    "    database=json_data['database']  # database\n",
    "    train_dict={}  # format: {id:{'annotations':[{\"segment\":[a, b]}, {\"segment\":[c, d]}]} }\n",
    "    val_dict={}\n",
    "    test_dict={}  \n",
    "    for video_name in database.keys():\n",
    "        video_info=database[video_name]  # video id\n",
    "        video_new_info={}\n",
    "        video_subset=video_info[\"subset\"]\n",
    "        video_new_info['annotations']=video_info['annotations']\n",
    "        if video_subset==\"training\":\n",
    "            train_dict[video_name]=video_new_info\n",
    "        elif video_subset==\"validation\":\n",
    "            val_dict[video_name]=video_new_info\n",
    "        elif video_subset==\"testing\":\n",
    "            test_dict[video_name]=video_new_info\n",
    "    return train_dict,val_dict,test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dict, val_dict, test_dict = getDatasetDict()  # all the datasets in meta.json\n",
    "print(len(train_dict))\n",
    "print(len(val_dict))\n",
    "print(len(test_dict))\n",
    "\n",
    "json_data= load_json(\"/home/kesci/work/Broad/INFO/meta.json\")\n",
    "database=json_data['database']\n",
    "\n",
    "train_dir = '/mnt/BROAD-datasets/video/training'\n",
    "val_dir = '/mnt/BROAD-datasets/video/validation'\n",
    "test_dir = '/mnt/BROAD-datasets/video/testing'\n",
    "\n",
    "train_id_list = [name.split('.')[0] for name in os.listdir(train_dir)]  # train video id list in first stage (124)\n",
    "val_id_list = [name.split('.')[0] for name in os.listdir(val_dir)]  # val video id list in first stage(115)\n",
    "test_id_list = [name.split('.')[0] for name in os.listdir(test_dir)] # test video id list in first stage(114)\n",
    "assert len(train_id_list)==124\n",
    "assert len(val_id_list)==115\n",
    "assert len(test_id_list)==114\n",
    "\n",
    "train_gt_dict = {key: value for key, value in train_dict.items() if key in train_id_list}  # train gt dict\n",
    "val_gt_dict = {key: value for key, value in val_dict.items() if key in val_id_list}  # val gt dict\n",
    "# test_gt_list = {key: value for key, value in test_dict.items() if key in test_id_list}\n",
    "assert len(val_gt_dict)==115\n",
    "assert len(train_gt_dict)==124\n",
    "# assert len(test_gt_list)==114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = '/mnt/BROAD-datasets/video/training'\n",
    "val_dir = '/mnt/BROAD-datasets/video/validation'\n",
    "test_dir = '/mnt/BROAD-datasets/video/testing'\n",
    "\n",
    "train_data_dic = dict()\n",
    "train_label_dic =dict()\n",
    "val_data_dic = dict()\n",
    "val_label_dic = dict()\n",
    "\n",
    "train_feature_length_list = []  # frame of each video\n",
    "train_video_id_list = []  # id of each video\n",
    "train_segment_length_list = []  # length of segment\n",
    "train_gt_length_list = []  # number of true frame\n",
    "\n",
    "for video_id in train_id_list:\n",
    "    train_video_id_list.append(video_id)\n",
    "    file = os.path.join(train_dir, '{}.pkl'.format(video_id))\n",
    "    feature = pd.read_pickle(file)\n",
    "    feature_len = len(feature)\n",
    "    train_feature_length_list.append(feature_len)\n",
    "    train_seg = np.array([_['segment'] for _ in train_gt_dict[video_id]['annotations']]).astype(np.int)\n",
    "    train_segment_length_list.append(len(train_seg))\n",
    "#     print(train_seg)\n",
    "    label = np.zeros(feature_len)\n",
    "    for seg in train_seg:\n",
    "        label[seg[0]:seg[1]] = 1\n",
    "    train_gt_length_list.append(sum(label==1))\n",
    "    \n",
    "    sample_inds = np.array(range(0, feature_len, 10))\n",
    "    train_data_dic[video_id] = feature[sample_inds]\n",
    "    train_label_dic[video_id] = label[sample_inds]\n",
    "    \n",
    "# df=pd.DataFrame()\n",
    "# df['video_id'] = video_id_list\n",
    "# df['feature_length'] = feature_length_list\n",
    "# df['segment_length'] = segment_length_list\n",
    "# df['gt_length'] = gt_length_list\n",
    "# df.to_csv(\"/home/kesci/work/Broad/INFO/train_video_info.csv\",index=False)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_feature_length_list = []  # frame of each video\n",
    "val_video_id_list = []  # id of each video\n",
    "val_segment_length_list = []  # length of segment\n",
    "val_gt_length_list = []  # number of true frame\n",
    "\n",
    "for video_id in val_id_list:\n",
    "    val_video_id_list.append(video_id)\n",
    "    file = os.path.join(val_dir, '{}.pkl'.format(video_id))\n",
    "    feature = pd.read_pickle(file)\n",
    "    feature_len = len(feature)\n",
    "    val_feature_length_list.append(feature_len)\n",
    "    val_seg = np.array([_['segment'] for _ in val_gt_dict[video_id]['annotations']]).astype(np.int)\n",
    "    val_segment_length_list.append(len(val_seg))\n",
    "#     print(train_seg)\n",
    "    label = np.zeros(feature_len)\n",
    "    for seg in val_seg:\n",
    "        label[seg[0]:seg[1]] = 1\n",
    "    val_gt_length_list.append(sum(label==1))\n",
    "    \n",
    "    val_data_dic[video_id] = feature\n",
    "    val_label_dic[video_id] = label\n",
    "    \n",
    "# df=pd.DataFrame()\n",
    "# df['video_id'] = video_id_list\n",
    "# df['feature_length'] = feature_length_list\n",
    "# df['segment_length'] = segment_length_list\n",
    "# df['gt_length'] = gt_length_list\n",
    "# df.to_csv(\"/home/kesci/work/Broad/INFO/val_video_info.csv\",index=False)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.concatenate([train_data_dic[_] for _ in train_id_list])\n",
    "print(train_data.shape)\n",
    "print(type(train_data))\n",
    "train_label = np.concatenate([train_label_dic[_] for _ in train_id_list])\n",
    "print(train_label.shape)\n",
    "print(type(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(val_id_list==val_video_id_list )\n",
    "\n",
    "val_infer_data = val_data_dic[val_id_list[0]]\n",
    "val_infer_label = val_label_dic[val_id_list[0]]\n",
    "\n",
    "print(val_infer_label)\n",
    "# print(val_infer_data)\n",
    "print(val_infer_label[170:220])\n",
    "infer_data = val_infer_data[170:220, :]\n",
    "infer_label = val_infer_label[170:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import paddle.v2 as paddle\n",
    "\n",
    "def multilayer_perception(img):\n",
    "    hidden1 = paddle.layer.fc(input=img, \n",
    "                              size=256, \n",
    "                              act=paddle.activation.Relu())\n",
    "    hidden2 = paddle.layer.fc(input=hidden1, \n",
    "                           size=512, \n",
    "                           act=paddle.activation.Relu())\n",
    "    predict = paddle.layer.fc(input=hidden2, \n",
    "                              size=2, \n",
    "                              act=paddle.activation.Softmax())\n",
    "    return predict\n",
    "\n",
    "paddle.init(use_gpu=False, trainer_count=1)\n",
    "features = paddle.layer.data(name='feature', \n",
    "                          type=paddle.data_type.dense_vector(2048))\n",
    "labels = paddle.layer.data(name='label', \n",
    "                          type=paddle.data_type.integer_value(2))\n",
    "predict = multilayer_perception(features)\n",
    "cost = paddle.layer.classification_cost(input=predict, label=labels)\n",
    "parameters = paddle.parameters.create(cost)\n",
    "optimizer = paddle.optimizer.Momentum(\n",
    "    learning_rate=0.1/128.0, \n",
    "    momentum=0.9, \n",
    "    regularization=paddle.optimizer.L2Regularization(rate=0.0005*128))\n",
    "trainer = paddle.trainer.SGD(cost=cost, \n",
    "                             parameters=parameters, \n",
    "                             update_equation=optimizer)\n",
    "\n",
    "def feature_reader_creator(feature, label):\n",
    "    def reader():\n",
    "        for i in xrange(len(feature)):\n",
    "            yield feature[i, :], int(label[i]) # a single entry of data is created each time\n",
    "    return reader\n",
    "\n",
    "from paddle.v2.plot import Ploter\n",
    "\n",
    "train_title = \"Train cost\"\n",
    "test_title = \"Test cost\"\n",
    "cost_ploter = Ploter(train_title, test_title)\n",
    "\n",
    "step = 0\n",
    "\n",
    "# event_handler to plot a figure\n",
    "def event_handler_plot(event):\n",
    "    global step\n",
    "    if isinstance(event, paddle.event.EndIteration):\n",
    "        if step % 100 == 0:\n",
    "            cost_ploter.append(train_title, step, event.cost)\n",
    "            cost_ploter.plot()\n",
    "        step += 1\n",
    "#     if isinstance(event, paddle.event.EndPass):\n",
    "#         # save parameters\n",
    "#         with open('params_pass_%d.tar' % event.pass_id, 'w') as f:\n",
    "#             trainer.save_parameter_to_tar(f)\n",
    "\n",
    "#         result = trainer.test(reader=paddle.batch(\n",
    "#             paddle.dataset.mnist.test(), batch_size=128))\n",
    "#         cost_ploter.append(test_title, step, result.cost)\n",
    "\n",
    "def event_handler(event):\n",
    "    if isinstance(event, paddle.event.EndIteration):\n",
    "        if event.batch_id % 100 == 0:\n",
    "            print \"\\nPass %d, Batch %d, Cost %f, %s\" % (\n",
    "                event.pass_id, event.batch_id, event.cost, event.metrics)\n",
    "        else:\n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "#     if isinstance(event, paddle.event.EndPass):\n",
    "#         # save parameters\n",
    "#         with open('params_pass_%d.tar' % event.pass_id, 'w') as f:\n",
    "#             trainer.save_parameter_to_tar(f)\n",
    "\n",
    "#         result = trainer.test(\n",
    "#             reader=paddle.batch(\n",
    "#                 paddle.dataset.cifar.test10(), batch_size=128),\n",
    "#             feeding=feeding)\n",
    "#         print \"\\nTest with Pass %d, %s\" % (event.pass_id, result.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feeding={'feature': 0,'label': 1}\n",
    "\n",
    "reader = feature_reader_creator(train_data, train_label)\n",
    "# shuffle_reader = paddle.reader.shuffle(reader,buf_size= 32)\n",
    "trainer.train(paddle.batch(reader, batch_size=32), feeding=feeding, event_handler=event_handler_plot, num_passes=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(val_infer_data)):\n",
    "    test_data.append(val_infer_data[i,:])\n",
    "probs = paddle.infer(\n",
    "    output_layer=predict, parameters=parameters, input=test_data)\n",
    "lab = np.argsort(-probs) # probs and lab are the results of one batch data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_label = lab[:, 0]\n",
    "for i in range(len(val_infer_label) / 35):\n",
    "    print(pred_label[i*35:i*35+35])\n",
    "    print(val_infer_label[i*35:i*35+35].astype(int))\n",
    "    print('*'*10 + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_video_info = pd.read_csv('/home/kesci/work/Broad/INFO/train_video_info.csv')\n",
    "train_video_info['negetive_length'] = train_video_info['feature_length'] - train_video_info['gt_length']\n",
    "train_video_info.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_video_info.gt_length.sum())\n",
    "print(train_video_info.feature_length.sum())\n",
    "train_video_info.gt_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
